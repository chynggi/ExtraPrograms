from music21 import converter, instrument, note, chord, midi, stream
import glob
import numpy as np
import matplotlib.pyplot as plt
from keras.utils import np_utils
from keras.models import Sequential
from keras.layers import Dense, Input, LSTM, Dropout, Activation
from keras.callbacks import EarlyStopping, ModelCheckpoint
from keras.models import load_model

def MusicComposer(modelfile,midi,Log):
    
    # Let's use One Hot Encoding for each of the notes and create an array as such of sequences. 
    #Let's first assign an index to each of the possible notes
    
    
    
    note_dict = dict()
    f0 = open("pitches.txt",'r',encoding='utf-8')
    pitches = f0.read().splitlines()
    for x in pitches:
        Log(str(x))
    
    for i, note in enumerate(pitches):
        note_dict[note] = i
    #Log(str(note_dict)
    
    # Now let's construct sequences. Taking each note and encoding it as a numpy array with a 1 in the position of the note it has
    sequence_length = 50
    # Lets make a numpy array with the number of training examples, sequence length, and the length of the one-hot-encoding
    f1 = open("vocab_length.txt",'r',encoding='utf-8')
    vocab_length = f1.readline()
    vocab_length = int(vocab_length)
    f2 = open("number_notes.txt",'r',encoding='utf-8')
    number_notes = f2.readline()
    number_notes = int(number_notes)
    num_training = int(number_notes) - sequence_length
    
    input_notes = np.zeros((num_training, sequence_length, vocab_length))
    output_notes = np.zeros((num_training, vocab_length))
    
    
    
    # Make a dictionary going backwards (with index as key and the note as the value)
    backward_dict = dict()
    for note in note_dict.keys():
        index = note_dict[note]
        backward_dict[index] = note
    
    # pick a random sequence from the input as a starting point for the prediction
    n = np.random.randint(0, len(input_notes)-1)
    sequence = input_notes[n]
    start_sequence = sequence.reshape(1, sequence_length, vocab_length)
    output = []
    
    model = load_model(modelfile)
    
    # Let's generate a song of 1200 notes
    for i in range(0, 1200):
        newNote = model.predict(start_sequence, verbose=0)
        # Get the position with the highest probability
        index = np.argmax(newNote)
        encoded_note = np.zeros((vocab_length))
        encoded_note[index] = 1
        output.append(encoded_note)
        sequence = start_sequence[0][1:]
        start_sequence = np.concatenate((sequence, encoded_note.reshape(1, vocab_length)))
        start_sequence = start_sequence.reshape(1, sequence_length, vocab_length)
        
    
    # Now output is populated with notes in their string form
    for element in output:
        Log(str(element))
    
    
    # ### Convert to MIDI format
    # Code here to output to MIDI files taken from github repo https://github.com/Skuldur/Classical-Piano-Composer.
    
    # In[7]:
    
    
    import music21 as m21
    finalNotes = [] 
    for element in output:
        index = list(element).index(1)
        Log(str(index))
        Log(str(backward_dict))
        finalNotes.append(backward_dict[index])
        
    offset = 0
    output_notes = []
        
    # create note and chord objects based on the values generated by the model
    for pattern in finalNotes:
        # pattern is a chord
        if ('.' in pattern) or pattern.isdigit():
            notes_in_chord = pattern.split('.')
            notes = []
            for current_note in notes_in_chord:
                new_note = m21.note.Note(int(current_note))
                new_note.storedInstrument = instrument.Piano()
                notes.append(new_note)
            new_chord = chord.Chord(notes)
            new_chord.offset = offset
            output_notes.append(new_chord)
        # pattern is a note
        else:
            new_note = m21.note.Note(pattern)
            new_note.offset = offset
            new_note.storedInstrument = instrument.Piano()
            output_notes.append(new_note)
    
        # increase offset each iteration so that notes do not stack
        offset += 0.5
    
    midi_stream = stream.Stream(output_notes)
    
    midi_stream.write('midi', fp=midi)
    
    
    # In[ ]:
